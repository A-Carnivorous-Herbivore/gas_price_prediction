# -*- coding: utf-8 -*-
"""Copy of Deep Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hrLiZ8a4PXiERFXIkCWjOYz3oJDln4ds

There is a summary at the bottom of this notebook that summarizes the work done in this notebook for this milestone! (Comments are included with code cells along the way as well.)

## Initial Setup
"""

# !pip install netcdf4 pydap

import torch
import gdown
import random
import numpy as np
import pandas as pd
import xarray as xr
import xarray as xr
import datetime as dt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

"""## Setup Data

*Notes for this can be found in the Data Exploration notebook.*
"""

# set seed value for reproducibility
def set_seed(seed):
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    np.random.seed(seed)
    random.seed(seed)
seed = 42
set_seed(seed)

exports_url = "https://drive.google.com/file/d/1J27j-yAZhe9tiQiJbctpL44QJ97nA4sV/view?usp=drive_link"
imports_url = "https://drive.google.com/file/d/1HS8YdIXwkHTxnq0CzJzJX1wUi_dvtznM/view?usp=drive_link"
net_imports_url = "https://drive.google.com/file/d/1ibxyKMBfs1WFNuYyUkmxf9k9jC_zuniX/view?usp=drive_link"
gas_prices_url = "https://drive.google.com/file/d/1rODElv0oLcJGLZufTfoLFhastfiMaLfX/view?usp=sharing"
tavg_url = "https://drive.google.com/file/d/1l6RLFWmVHtsQP4nGPKta9zvJAiJR71DS/view?usp=sharing"

exports = pd.read_csv('https://drive.google.com/uc?export=download&id=' + exports_url.split('/')[-2], skiprows=2)
imports = pd.read_csv('https://drive.google.com/uc?export=download&id=' + imports_url.split('/')[-2], skiprows=2)
net_imports = pd.read_csv('https://drive.google.com/uc?export=download&id=' + net_imports_url.split('/')[-2], skiprows=2)
gas_prices = pd.read_csv('https://drive.google.com/uc?export=download&id=' + gas_prices_url.split('/')[-2], skiprows=2)

exports = exports.drop(columns=['Unnamed: 11'])
exports['Date'] = pd.to_datetime(exports['Date'])
imports = imports.drop(columns=['Unnamed: 36'])
imports['Date'] = pd.to_datetime(imports['Date'])
gas_prices['Date'] = pd.to_datetime(gas_prices['Date'])

# Last value of each df is always NaN
exports = exports[:-1]
imports = imports[:-1]
gas_prices = gas_prices[:-1]

export_columns = {}
for column in exports.columns:
  export_columns[column] = ' '.join(column.replace('Weekly U.S.', '').replace('Exports of', '').replace('(Thousand Barrels per Day)', '(Exports)').split())

import_columns = {}
for column in imports.columns:
  import_columns[column] = ' '.join(column.replace('Weekly U.S.', '').replace('Imports of', '').replace('(Thousand Barrels per Day)', '(Imports)').split())

exports = exports.rename(columns = export_columns)
imports = imports.rename(columns = import_columns)
gas_prices = gas_prices.rename(columns = {'Weekly U.S. All Grades All Formulations Retail Gasoline Prices  (Dollars per Gallon)': 'Gas Prices'})

# Merge
merged_df_all_features = pd.merge_asof(gas_prices, imports, on='Date', direction='backward')
merged_df_all_features = pd.merge_asof(merged_df_all_features, exports, on='Date', direction='backward')

# Find Net Imports (Similar to net_imports df but with all dates)
reduced_columns = ['Crude Oil', 'Total Petroleum Products', 'Crude Oil and Petroleum Products']
for col in reduced_columns:
  merged_df_all_features[col + ' (Net Imports)'] = merged_df_all_features[col + ' (Imports)'] - merged_df_all_features[col + ' (Exports)']

cols = ['Date', 'Gas Prices'] + [col + ' (Imports)' for col in reduced_columns] + [col + ' (Exports)' for col in reduced_columns] + [col + ' (Net Imports)' for col in reduced_columns]

merged_df_simple = merged_df_all_features[cols].copy()

for col in merged_df_simple.columns:
  if len(merged_df_simple[merged_df_simple[col].isna()]) > 0:
    print(f"Missing data for {col}:", len(merged_df_simple[merged_df_simple[col].isna()]))

merged_df_simple.loc[:, 'Total Petroleum Products (Exports)'] = merged_df_simple['Total Petroleum Products (Exports)'].ffill()
merged_df_simple.loc[:, 'Total Petroleum Products (Net Imports)'] = merged_df_simple['Total Petroleum Products (Exports)'] - merged_df_simple['Total Petroleum Products (Imports)']

for col in merged_df_simple.columns:
  if col not in ['Date']:
    merged_df_simple[f'{col}_diff_weekly'] = merged_df_simple[col].diff()
    merged_df_simple[f'{col}_diff_monthly'] = merged_df_simple[col] - merged_df_simple[col].shift(4)

"""# Deep Learning (RNN)"""

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

"""*We still focus on basic features for now.*"""

target_features = ['Gas Prices']
explanatory_features = ['Crude Oil (Imports)', 'Total Petroleum Products (Imports)', 'Crude Oil and Petroleum Products (Imports)', 'Crude Oil (Exports)', 'Total Petroleum Products (Exports)', 'Crude Oil and Petroleum Products (Exports)', 'Crude Oil (Net Imports)', 'Total Petroleum Products (Net Imports)', 'Crude Oil and Petroleum Products (Net Imports)']

"""First, we see if we can predict weekly changes in gas price."""

x_features = [diff + '_diff_weekly' for diff in explanatory_features]
X = merged_df_simple[x_features].copy()
for col in X.columns:
  X.loc[:, col] *= 100
y = merged_df_simple['Gas Prices_diff_weekly'].copy()
y *= 100
X = X.fillna(0)
y = y.fillna(0)

train_size = 0.7
validation_size = 0.15
test_size = 1 - train_size - validation_size

X_train = X[:int(train_size * len(X))]
y_train = y[:int(train_size * len(X))]

X_validation = X[int(train_size * len(X)) : int((train_size + validation_size) * len(X))]
y_validation = y[int(train_size * len(X)) : int((train_size + validation_size) * len(X))]

X_test = X[int((train_size + validation_size) * len(X)) : ]
y_test = y[int((train_size + validation_size) * len(X)) : ]

# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(1 - train_size), shuffle=True, random_state=seed)

# validation_ratio = validation_size / (validation_size + test_size)
# X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=(1 - validation_ratio), shuffle=True, random_state=seed)

print(f"Train size: {len(X_train)}, Validation size: {len(X_validation)}, Test size: {len(X_test)}")

"""## Baseline Model

*Baseline linear regression results for reference; note that the output result is magnified by 100 times for better illustration purpose.*
"""

lin_model = LinearRegression()
lin_model.fit(X_train, y_train)
print("Training error for linear regression:", mean_squared_error(lin_model.predict(X_train), y_train))
print("Validation error for linear regression:", mean_squared_error(lin_model.predict(X_validation), y_validation))

"""## RNN Investigation

*We created an RNN model that takes in inputs of window size 10, meaning that the sequence will be trained to 10 data points and mapped the final hidden embedding with a linear layer to predict the next interval oil price.*
"""

class RNN(nn.Module):
    def __init__(self, input_size, hidden_size=5, num_layers=2):
        super(RNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        batch_size = x.size(0)
        h0 = torch.zeros(self.rnn.num_layers, batch_size, self.rnn.hidden_size).to(x.device)
        out, _ = self.rnn(x, h0)
        out = out[:, -1, :]
        out = self.fc(out)
        return out

def create_sequences(data, targets, seq_length):
    sequences = []
    seq_targets = []
    for i in range(len(data) - seq_length):
        seq = data[i:i + seq_length]
        target = targets[i + seq_length]
        sequences.append(seq)
        seq_targets.append(target)
    return torch.stack(sequences), torch.tensor(seq_targets).reshape(-1, 1)

X_train_torch = torch.from_numpy(X_train.values).to(torch.float32)
X_validation_torch = torch.from_numpy(X_validation.values).to(torch.float32)
X_test_torch = torch.from_numpy(X_test.values).to(torch.float32)

y_train_torch = torch.from_numpy(y_train.values).reshape(-1,1).to(torch.float32)
y_validation_torch = torch.from_numpy(y_validation.values).reshape(-1,1).to(torch.float32)
y_test_torch = torch.from_numpy(y_test.values).reshape(-1,1).to(torch.float32)


sequence_length = 10 # Set window size
X_train_sequences, y_train_sequences = create_sequences(X_train_torch, y_train_torch, sequence_length)
X_validation_sequences, y_validation_sequences = create_sequences(X_validation_torch, y_validation_torch, sequence_length)
X_test_sequences, y_test_sequences = create_sequences(X_test_torch, y_test_torch, sequence_length)

print(f'X_train_sequences shape: {X_train_sequences.shape}')
print(f'y_train_sequences shape: {y_train_sequences.shape}')

"""*We trained the model with hidden_size as 20 and 5 layers; this reached extremely low error at 2.0808/100 = 0.010808 for training dataset. However, this is very bad for validation loss, at 38.0625/100 = 0.380625. Therefore, we have to tune the parameters.*"""

model = RNN(input_size=9, hidden_size=20, num_layers=5)  # Adjust `hidden_size` as needed
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
num_epochs = 200

for epoch in range(num_epochs):
    model.train()
    outputs = model(X_train_sequences)  # Pass in sequences for training
    loss = criterion(outputs, y_train_sequences)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

with torch.no_grad():
    validation_outputs = model(X_validation_sequences)
    validation_loss = criterion(validation_outputs, y_validation_sequences)
    print(f'Validation Loss: {validation_loss.item():.4f}')

"""*As we lowered the complexity of the model, with hidden_size at 5 and num_layers at 2, we achived a better balance between training error and validation error. We fine-tuned the parameters using training and validation output, and this seems to be the best balance we can find. At last, we tested the model of test dataset, which gives a quite similar result, proving the accuracy and robustness of the model.*"""

model = RNN(input_size=9, hidden_size=5, num_layers=2)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
num_epochs = 200

for epoch in range(num_epochs):
    model.train()
    outputs = model(X_train_sequences)
    loss = criterion(outputs, y_train_sequences)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

with torch.no_grad():
    validation_outputs = model(X_validation_sequences)
    validation_loss = criterion(validation_outputs, y_validation_sequences)
    print(f'Validation Loss: {validation_loss.item():.4f}')

with torch.no_grad():
    test_outputs = model(X_test_sequences)
    test_loss = criterion(test_outputs, y_test_sequences)
    print(f'Test Loss: {test_loss.item():.4f}')

"""*Let us now try different optimizer based on the best parameters we found out in the previous solution that used Adam optimzer. In the following case, we are using AdamW (Adam with weight decay for better regularization). We can see that there is not a significant difference.*"""

model = RNN(input_size=9, hidden_size=5, num_layers=2)
criterion = nn.MSELoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)
num_epochs = 200

for epoch in range(num_epochs):
    model.train()
    outputs = model(X_train_sequences)
    loss = criterion(outputs, y_train_sequences)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

with torch.no_grad():
    validation_outputs = model(X_validation_sequences)
    validation_loss = criterion(validation_outputs, y_validation_sequences)
    print(f'Validation Loss: {validation_loss.item():.4f}')

with torch.no_grad():
    test_outputs = model(X_test_sequences)
    test_loss = criterion(test_outputs, y_test_sequences)
    print(f'Test Loss: {test_loss.item():.4f}')

"""*Let us try the famous RMSProp. We can see that for this task, there is no proof that different optimizer can affect the result.*

"""

model = RNN(input_size=9, hidden_size=5, num_layers=2)
criterion = nn.MSELoss()
optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, alpha=0.90)
num_epochs = 200

for epoch in range(num_epochs):
    model.train()
    outputs = model(X_train_sequences)
    loss = criterion(outputs, y_train_sequences)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch + 1) % 20 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

with torch.no_grad():
    validation_outputs = model(X_validation_sequences)
    validation_loss = criterion(validation_outputs, y_validation_sequences)
    print(f'Validation Loss: {validation_loss.item():.4f}')

with torch.no_grad():
    test_outputs = model(X_test_sequences)
    test_loss = criterion(test_outputs, y_test_sequences)
    print(f'Test Loss: {test_loss.item():.4f}')

"""## Mini-batch Learning

*We now investigate the effects of mini-batch learning. We find that the results obtained when using mini-batch learning are not much different from those achieved using batch learning. Note that multiple batch sizes and optimizers were tried.*
"""

from torch.utils.data import Dataset, DataLoader

class CustomDataset(Dataset):
  def __init__(self, data, labels):
    self.data = data
    self.labels = labels

  def __len__(self):
    return len(self.data)

  def __getitem__(self, index):
    return self.data[index], self.labels[index]

batch_size = 32
dataset = CustomDataset(X_train_sequences, y_train_sequences)
data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

model = RNN(input_size=9, hidden_size=5, num_layers=2)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
num_epochs = 200

for epoch in range(num_epochs):
  for (x_data, y_data) in data_loader:
    model.train()
    outputs = model(x_data)
    loss = criterion(outputs, y_data)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

  if (epoch + 1) % 100 == 0:
      with torch.no_grad():
        l = criterion(model(X_train_sequences), y_train_sequences).item()
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {l:.4f}')

with torch.no_grad():
    train_outputs = model(X_train_sequences)
    train_loss = criterion(train_outputs, y_train_sequences)

    validation_outputs = model(X_validation_sequences)
    validation_loss = criterion(validation_outputs, y_validation_sequences)

    test_outputs = model(X_test_sequences)
    test_loss = criterion(test_outputs, y_test_sequences)

    print(f'Training Loss: {train_loss.item():.4f}')
    print(f'Validation Loss: {validation_loss.item():.4f}')
    print(f'Test Loss: {test_loss.item():.4f}')

"""## Hyper-Paramater Training

*We now perform grid search to find the best parameters for hidden sizes, number of layers and learning rate to reduce the validation loss. This will allow us to select the final model with a set of fixed paramaters. Our best combination of parameters are hidden_size=4, num_layers=2, lr=0.01*
"""

import itertools
import torch.nn as nn
import torch.optim as optim

hidden_sizes = [4, 5, 6]
num_layers_list = [2, 3, 4]
learning_rates = [0.01, 0.001, 0.0001]
num_epochs = 200

results = []

for hidden_size, num_layers, lr in itertools.product(hidden_sizes, num_layers_list, learning_rates):
    print(f"Testing combination: hidden_size={hidden_size}, num_layers={num_layers}, lr={lr}")

    model = RNN(input_size=9, hidden_size=hidden_size, num_layers=num_layers)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    for epoch in range(num_epochs):
      for (x_data, y_data) in data_loader:
        model.train()
        outputs = model(x_data)
        loss = criterion(outputs, y_data)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

      if (epoch + 1) % 100 == 0:
          with torch.no_grad():
            l = criterion(model(X_train_sequences), y_train_sequences).item()
            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {l:.4f}')

    model.eval()

    with torch.no_grad():
        validation_outputs = model(X_validation_sequences)
        validation_loss = criterion(validation_outputs, y_validation_sequences)

    results.append((hidden_size, num_layers, lr, validation_loss.item()))
    print(f"Validation Loss: {validation_loss.item():.4f}")

best_combination = min(results, key=lambda x: x[3])
print(f"Best combination: hidden_size={best_combination[0]}, num_layers={best_combination[1]}, lr={best_combination[2]}, validation_loss={best_combination[3]:.4f}")

"""### Model with Best Parameters"""

model = RNN(input_size=9, hidden_size=5, num_layers=2)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
num_epochs = 200

for epoch in range(num_epochs):
  for (x_data, y_data) in data_loader:
    model.train()
    outputs = model(x_data)
    loss = criterion(outputs, y_data)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

  if (epoch + 1) % 100 == 0:
      with torch.no_grad():
        l = criterion(model(X_train_sequences), y_train_sequences).item()
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {l:.4f}')

with torch.no_grad():
    train_outputs = model(X_train_sequences)
    train_loss = criterion(train_outputs, y_train_sequences)

    validation_outputs = model(X_validation_sequences)
    validation_loss = criterion(validation_outputs, y_validation_sequences)

    test_outputs = model(X_test_sequences)
    test_loss = criterion(test_outputs, y_test_sequences)

    print(f'Training Loss: {train_loss.item():.4f}')
    print(f'Validation Loss: {validation_loss.item():.4f}')
    print(f'Test Loss: {test_loss.item():.4f}')

"""# Summary

Due to the time-series and potentially self-exciting behavior of gas prices, we explored using different RNNs for the prediction of future gas prices. Throughout, we investigated
- **Model complexity**: By using a large hidden size and number of layers, we could achieve very low training error but had a very high validation error due to overfitting. We found a combination of parameters to reduce training and validation error was around a hidden size of 5 and 2 layers ib our initial exploration.
- **Learning Rate**: As usual, we varied learning rate depending on the convergence behavior of the training error. Learning rates of around 0.01 was able to stabalize training and validation loss. We left further tuning this to hyper-parameter tuning.
- **Optimizers**: We tried Adam, AdamW, and RMSprop optimizers. It seems Adam led to the smallest validation error, however the differences between the different optimizers was not super significant.
- **Mini-batch learning**: Despite using mulitple batch sizes (with multiple learning rates, optimizers, and model complexities), we were not able to achieve significantly better results than those achieved with batch learning.
- **Hyper-parameter training**: We used grid search to find the best hyper-paramaters for our model trainined with mini batches. We found that a model with a hidden size of 4 and 2 layers trained using a learning rate of 0.01 gives the best validation error. We received the lowest values for our test set for these paramaters.

Future work:
- For the next milestone, we hope to evaluate feature importance so we can remove features to reduce overfitting or construct features that will be beneficial for predicting gas prices.
- We can investigate predicting gas prices over different time horizons (currently, we are focused on 1-week predictions).
- Due to issues like vanishing gradients, we may consider using LSTM or GRU architectures. The literature seems to suggest that LSTM networks might lead to better results.
"""